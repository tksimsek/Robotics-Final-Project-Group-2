{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Arm Sorting Project Guide\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this project, you will implement a control pipeline for a robot arm that sorts objects based on their color â€” which is either red or blue. The sorting process is simple: the robot should move objects to the mat corresponding to their color. \n",
    "\n",
    "![This is the starting point](images/locobot_sorting.png \"Simulation setup\")\n",
    "\n",
    "\n",
    "### Available Objects:\n",
    "1. **Simple Task (Graspable Objects)**: \n",
    "   - Small cube (red/blue)\n",
    "   - Small ball (red/blue)\n",
    "   - Small cylinder (red/blue)\n",
    "\n",
    "2. **Complex Task (Non-Graspable Objects)**:\n",
    "   - Big ball (red/blue): This object cannot be grasped; the robot should push it.\n",
    "   - Big cylinder (red/blue): The robot cannot grasp it either; it should knock it over and push it.\n",
    "\n",
    "Your goal is to make the robot successfully sort these objects by moving them to the correct mat (based on color).\n",
    "\n",
    "## Project Launch\n",
    "\n",
    "To launch the simulation environment with all the objects, use the following command:\n",
    "```bash\n",
    "roslaunch locobot_simulation simulation_project_allobjects.launch\n",
    "```\n",
    "\n",
    "If you wish to launch the project with MoveIt, then you can run the following command:\n",
    "```bash\n",
    "roslaunch locobot_moveit xslocobot_moveit.launch\n",
    "```\n",
    "\n",
    "You can see launch file for more details.\n",
    "\n",
    "\n",
    "## Perception Setup\n",
    "\n",
    "The objects are detected using a **logical camera**, which publishes data on this ROS topic:\n",
    "```\n",
    "/gazebo/locobot/camera/logical_camera_image\n",
    "```\n",
    "Note that the camera only captures what the robot is looking at. You need to move the camera to face the objects to get their properties.\n",
    "\n",
    "So, as one of the first things, you will need to subscribe to this topic to get the object location (given compared to the world frame).\n",
    "\n",
    "---\n",
    "\n",
    "## Task Breakdown\n",
    "\n",
    "You will need to create a ros package (or a set of packages) in the catkin_ws workspace. You will need to do the following tasks:\n",
    "\n",
    "### Step 1: Set up MoveIt with the Robot Arm\n",
    "- **Goal**: Configure MoveIt to control the robot arm.\n",
    "- **MoveIt** will help you generate motion plans for picking up objects and moving the arm accurately.\n",
    "  \n",
    "### Step 2: Aim the Camera at the Objects\n",
    "- **Goal**: Use the camera to detect and identify the color and type of the objects.\n",
    "- Move the robot arm or the camera head to focus on the objects so they can be detected by the logical camera.\n",
    "\n",
    "### Step 3: Solve the Pickup for Simple Objects\n",
    "- **Goal**: Implement the logic to pick up **graspable objects** (small cube, ball, and cylinder).\n",
    "  - Use the camera data to locate the objects.\n",
    "  - Control the arm to grasp and move the objects to the correct colored mat.\n",
    "\n",
    "### Step 4: (Optional) Solve the Complex Objects\n",
    "- **Goal**: Implement logic to interact with **non-graspable objects** (big ball and big cylinder).\n",
    "  - **Big ball**: Push the object to its corresponding mat.\n",
    "  - **Big cylinder**: Knock it over and push it to the mat. Or be creative :)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Grading\n",
    "\n",
    "The project work yields 20 points in total which is distributed based on five metrics:\n",
    "- Performance  (Task completion time, accuracy)\n",
    "- Creativity of the Solution (Using learning-based methods or methods not covered in the lecture)\n",
    "- Code (Including documentation)\n",
    "- Presentation\n",
    "- Individual Contribution\n",
    "\n",
    "On each metric you can earn a up to 4 points, adding up to a total of 20 points, which corresponds to 20% of your final grade in the course.\n",
    "\n",
    "The rubric for how to earn maximum point for each aspect will be shared later.\n",
    "\n",
    "## Tips\n",
    "- Focus first on solving the graspable objects to build familiarity with MoveIt and the camera.\n",
    "- For complex objects, think creatively about how the robot can push or knock objects without grasping them.\n",
    "- Test frequently in Gazebo to ensure your robot arm moves smoothly and interacts properly with the objects.\n",
    "- Feel free to use learning-based solutions, using the learning path of Machine Learning available on this platform: https://app.theconstruct.ai/learning-paths/machine-learning-for-robots\n",
    "\n",
    "Good luck, and enjoy building your control pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
